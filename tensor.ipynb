{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "vector = np.array([1, 2, 3])  # 1D 向量\n",
    "matrix_3x1 = vector.reshape(3, 1)  # 变成 3×1 矩阵\n",
    "\n",
    "print(matrix_3x1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]]\n",
      "(1, 3)\n",
      "[[1]\n",
      " [2]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "matrix_T = matrix_3x1.T\n",
    "print(matrix_T)\n",
    "print(matrix_T.shape)\n",
    "print(matrix_3x1.T.T)  # 逆转两次，得到原来的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A + B =\n",
      " [[ 6  8]\n",
      " [10 12]]\n",
      "A - B =\n",
      " [[-4 -4]\n",
      " [-4 -4]]\n",
      "2 * A =\n",
      " [[2 4]\n",
      " [6 8]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 定义两个相同形状的张量（矩阵）\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([[5, 6], [7, 8]])\n",
    "\n",
    "# 加法\n",
    "C_add = A + B\n",
    "\n",
    "# 减法\n",
    "C_sub = A - B\n",
    "\n",
    "# 数乘\n",
    "C_mul = 2 * A\n",
    "\n",
    "print(\"A + B =\\n\", C_add)\n",
    "print(\"A - B =\\n\", C_sub)\n",
    "print(\"2 * A =\\n\", C_mul)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 運算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A+B=\n",
      " [[ 3  7]\n",
      " [11 15]]\n",
      "A-B=\n",
      " [[1 1]\n",
      " [1 1]]\n",
      "3*A=\n",
      " [[ 6 12]\n",
      " [18 24]]\n",
      "A*B=\n",
      " [[ 2 12]\n",
      " [30 56]]\n",
      "矩阵乘法 A @ B =\n",
      " [[22 34]\n",
      " [46 74]]\n",
      "Hadamard 乘法 A * B =\n",
      " [[ 2 12]\n",
      " [30 56]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "A = np.array([[2, 4], [6, 8]])\n",
    "B = np.array([[1, 3], [5, 7]])\n",
    "print(\"A+B=\\n\",A+B)\n",
    "print(\"A-B=\\n\",A-B)\n",
    "print(\"3*A=\\n\",3*A)\n",
    "print(\"A*B=\\n\",A*B)\n",
    "import numpy as np\n",
    "\n",
    "C_matmul = np.matmul(A, B)  # 正确的矩阵乘法\n",
    "C_hadamard = A * B  # 逐元素相乘（Hadamard Product）\n",
    "\n",
    "print(\"矩阵乘法 A @ B =\\n\", C_matmul)\n",
    "print(\"Hadamard 乘法 A * B =\\n\", C_hadamard)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A =\n",
      " [[0.09271478 0.69008301 0.66174906]\n",
      " [0.75198085 0.0555715  0.46616198]\n",
      " [0.82186625 0.00738602 0.56115767]]\n",
      "A @ A =\n",
      " [[1.07139446 0.10721754 0.75438994]\n",
      " [0.49463125 0.52546048 0.78511831]\n",
      " [0.54294985 0.57171111 0.86221024]]\n",
      "A.T @ A =\n",
      " [[1.24953537 0.11183992 0.87309536]\n",
      " [0.11183992 0.4793573  0.48671182]\n",
      " [0.87309536 0.48671182 0.97011675]]\n"
     ]
    }
   ],
   "source": [
    "## 用 NumPy 计算上面数学题的所有运算。生成一个 3×3 随机矩阵，并计算：\n",
    "## 1.该矩阵与自身的点积2.该矩阵的 转置 与原矩阵的乘积\n",
    "import numpy as np\n",
    "A = np.random.rand(3, 3)\n",
    "print(\"A =\\n\", A)\n",
    "print(\"A @ A =\\n\", A @ A)\n",
    "print(\"A.T @ A =\\n\", A.T @ A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.張量操作：請使用 numpy 建立一個 4 維張量，並取出其前兩個維度的切片。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "降維後張量形狀: (2, 2)\n",
      "[[0.95835573 0.20930656]\n",
      " [0.49774427 0.56705293]]\n",
      "新的切片形狀: (2, 2, 2)\n",
      "[[[0.95835573 0.31424596]\n",
      "  [0.20930656 0.89349396]]\n",
      "\n",
      " [[0.49774427 0.50333139]\n",
      "  [0.56705293 0.55567062]]]\n"
     ]
    }
   ],
   "source": [
    "## 1.張量操作：請使用 numpy 建立一個 4 維張量\n",
    "T = np.random.rand(2,2,2,2)   # 4D 張量\n",
    "T_slice_2D = T[:, :, 0, 0]  # 只選取第一個 2x2 子矩陣\n",
    "print(\"降維後張量形狀:\", T_slice_2D.shape)  # (2,2)\n",
    "print(T_slice_2D)  # 顯示選取的子矩陣\n",
    "T_slice_specific = T[:, :, 0, :]  # 取出第3維索引 0 的所有數據\n",
    "print(\"新的切片形狀:\", T_slice_specific.shape)  # (2,2,2)\n",
    "print(T_slice_specific)  # 顯示選取的子矩陣\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.矩陣乘積態（MPS）應用：嘗試用 MPS 近似一個 4x4x4 張量，看看誤差如何變化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "誤差： 3.4619776364910093\n"
     ]
    }
   ],
   "source": [
    "#2.矩陣乘積態（MPS）應用：嘗試用 MPS 近似一個 4x4x4 張量，看看誤差如何變化\n",
    "# 隨機生成一個 4x4x4 張量\n",
    "T0 = np.random.rand(4, 4, 4)\n",
    "# 隨機生成三個矩陣                  \n",
    "M1 = np.random.rand(4, 2)   # M1: 第一層矩陣\n",
    "M2 = np.random.rand(2, 4, 2) # M2: 連結中間的矩陣\n",
    "M3 = np.random.rand(2, 4)   # M3: 最後一層矩陣\n",
    "# 張量重建\n",
    "T_approx = np.einsum('ia,ajb,bc->ijc', M1, M2, M3)  # MPS 運算\n",
    "# 檢查誤差\n",
    "error = np.linalg.norm(T0 - T_approx)\n",
    "print(\"誤差：\", error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  交叉插值的示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "矩陣交叉插值誤差: 2.405259\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 生成一個 6x6 的矩陣\n",
    "np.random.seed(0)\n",
    "A = np.random.rand(6, 6)\n",
    "\n",
    "# 選取某些行與列作為 pivots\n",
    "rows = [0, 2, 4]  # Pivot rows\n",
    "cols = [1, 3, 5]  # Pivot columns\n",
    "\n",
    "# 取出 C, W, R\n",
    "C = A[:, cols]  # 取出這些列\n",
    "R = A[rows, :]  # 取出這些行\n",
    "W = A[np.ix_(rows, cols)]  # 交叉區域\n",
    "\n",
    "# 近似重建 A\n",
    "A_approx = C @ np.linalg.pinv(W) @ R\n",
    "\n",
    "# 計算誤差\n",
    "error = np.linalg.norm(A - A_approx, 'fro')\n",
    "print(f\"矩陣交叉插值誤差: {error:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCI 近似誤差: 6.468224\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# 生成一個 10x10x10 的隨機函數張量\n",
    "np.random.seed(42)\n",
    "T = np.random.rand(10, 10, 10)\n",
    "\n",
    "# 張量轉換為矩陣展開 (10, 100)\n",
    "T_matrix = T.reshape(10, -1)\n",
    "\n",
    "# 使用截斷 SVD 來近似\n",
    "svd = TruncatedSVD(n_components=4)  # 只保留 3 個主要特徵\n",
    "T_approx = svd.fit_transform(T_matrix) @ svd.components_\n",
    "\n",
    "# 轉回 10x10x10 張量\n",
    "T_approx = T_approx.reshape(10, 10, 10)\n",
    "\n",
    "# 計算誤差\n",
    "error = np.linalg.norm(T - T_approx)\n",
    "print(f\"TCI 近似誤差: {error:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "近似矩陣 A_approx:\n",
      "[[0.30096357 0.70817209 0.0673506  0.58217046 0.34588306 0.62091552\n",
      "  0.04574203 0.87153681]\n",
      " [0.97348897 0.96887786 0.74965183 0.13008624 0.7582632  0.02458692\n",
      "  0.02212355 0.32361022]\n",
      " [0.48864319 0.77040742 0.68329538 0.44590271 0.27362667 0.9971245\n",
      "  0.4261813  0.45138702]\n",
      " [0.16362382 0.79480955 0.69368223 0.22076961 0.08238105 0.6804993\n",
      "  0.65451121 0.27325953]\n",
      " [0.95086356 0.15105789 0.4323348  0.94361592 0.41972732 0.63852595\n",
      "  0.3975944  0.2742152 ]\n",
      " [0.98397765 0.40933401 0.8940992  0.22995461 0.2131047  0.03113408\n",
      "  0.65166683 0.36852634]\n",
      " [0.86435825 0.47320991 0.96819343 0.18552552 0.86862317 0.77659685\n",
      "  0.77092184 0.84478323]\n",
      " [0.76102399 0.62622032 0.13124488 0.03252618 0.92084785 0.61665031\n",
      "  0.79653729 0.48152235]]\n",
      "Frobenius Norm 誤差: 1.47137e-14\n"
     ]
    }
   ],
   "source": [
    "A = np.random.rand(8, 8)\n",
    "def cross_interpolation(A, rank=2):\n",
    "    \"\"\" 矩陣交叉插值 (Cross Interpolation, CI) 方法 \"\"\"\n",
    "    m, n = A.shape\n",
    "\n",
    "    # 1. 選擇 rank 個行與列 (這裡隨機選擇)\n",
    "    row_idx = np.random.choice(m, rank, replace=False)\n",
    "    col_idx = np.random.choice(n, rank, replace=False)\n",
    "\n",
    "    # 2. 取得交叉區塊 P\n",
    "    P = A[np.ix_(row_idx, col_idx)]\n",
    "    \n",
    "    # 3. 取得 C 和 R\n",
    "    C = A[:, col_idx]  # 取選定列\n",
    "    R = A[row_idx, :]  # 取選定行\n",
    "\n",
    "    # 4. 計算 U = P^(-1)\n",
    "    P_inv = np.linalg.pinv(P)  # 使用偽逆以應對可能的數值問題\n",
    "\n",
    "    # 5. 近似 A\n",
    "    A_approx = C @ P_inv @ R\n",
    "\n",
    "    return A_approx, row_idx, col_idx\n",
    "\n",
    "# 執行 CI 方法\n",
    "A_approx, row_idx, col_idx = cross_interpolation(A, rank=8)\n",
    "\n",
    "# 顯示近似結果\n",
    "print(\"近似矩陣 A_approx:\")\n",
    "print(A_approx)\n",
    "# 計算誤差\n",
    "error = np.linalg.norm(A - A_approx, ord='fro')\n",
    "print(f\"Frobenius Norm 誤差: {error:.5e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 為什麼 TCI 只需要部分數據就能學習張量結構？\n",
    "## 與 PCA 相比，TCI 的優勢與劣勢是什麼？\n",
    "## 嘗試用 TCI 來近似一個更高維度的函數，例如 20x20x20 張量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCI 近似誤差: 10.982050\n"
     ]
    }
   ],
   "source": [
    "#1.為什麼 TCI 只需要部分數據就能學習張量結構？TCI可以反覆更新，直到誤差收斂\n",
    "#與 PCA 相比，TCI 的優勢與劣勢是什麼？TCI 可以處理高維度數據，但是計算量較大，且需要調參，而 PCA 計算量小，但是只能處理低維度數據，且需要完整數據。\n",
    "#嘗試用 TCI 來近似一個更高維度的函數，例如 20x20x20 張量。\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "np.random.seed(47896512)\n",
    "# 生成一個20x20x20 張量 的隨機函數張量\n",
    "T=np.random.rand(20,20,20)\n",
    "# 張量轉換為矩陣展開 (20, 400)\n",
    "T_matrix = T.reshape(20, -1)  \n",
    "# 使用截斷 SVD 來近似  \n",
    "svd = TruncatedSVD(n_components=15)# 只保留 11 個主要特徵\n",
    "T_approx = svd.fit_transform(T_matrix) @ svd.components_   \n",
    " # 轉回 20x20x20 張量\n",
    "T_approx = T_approx.reshape(20, 20, 20)\n",
    "# 計算誤差\n",
    "error = np.linalg.norm(T - T_approx)\n",
    "print(f\"TCI 近似誤差: {error:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCI 近似誤差: 25.0978852\n",
      "TCI 近似誤差: 24.1737896\n",
      "TCI 近似誤差: 23.2390187\n",
      "TCI 近似誤差: 22.3152495\n",
      "TCI 近似誤差: 21.3855198\n",
      "TCI 近似誤差: 20.4565959\n",
      "TCI 近似誤差: 19.4969665\n",
      "TCI 近似誤差: 18.5273073\n",
      "TCI 近似誤差: 17.5391298\n",
      "TCI 近似誤差: 16.5334359\n",
      "TCI 近似誤差: 15.5301475\n",
      "TCI 近似誤差: 14.4659242\n",
      "TCI 近似誤差: 13.3479064\n",
      "TCI 近似誤差: 12.1552698\n",
      "TCI 近似誤差: 10.9820503\n",
      "TCI 近似誤差: 9.6773078\n",
      "TCI 近似誤差: 8.1810646\n",
      "TCI 近似誤差: 6.5443396\n",
      "TCI 近似誤差: 4.4784457\n",
      "TCI 近似誤差: 0.0000000\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 21):\n",
    "    svd = TruncatedSVD(n_components=i)\n",
    "    T_approx = svd.fit_transform(T_matrix) @ svd.components_   \n",
    " # 轉回 20x20x20 張量\n",
    "    T_approx = T_approx.reshape(20, 20, 20)\n",
    "# 計算誤差\n",
    "    error = np.linalg.norm(T - T_approx)\n",
    "    print(f\"TCI 近似誤差: {error:.7f}\")\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## real TCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCI 近似誤差: 0.000000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 生成一個 20x20x20 的張量\n",
    "np.random.seed(47896512)\n",
    "T = np.random.rand(20, 20, 20)\n",
    "n=20\n",
    "# 選擇 pivot 行列\n",
    "rows = np.random.choice(20, n, replace=False)  # 隨機選 n 個 pivot 行\n",
    "cols = np.random.choice(20, n, replace=False)  # 隨機選 n 個 pivot 列\n",
    "\n",
    "# 取出 C, R, W\n",
    "C = T[:, cols, :]  # 形狀: (20, 10, 20)\n",
    "R = T[rows, :, :]  # 形狀: (10, 20, 20)\n",
    "W = T[np.ix_(rows, cols, np.arange(20))]  # 形狀: (10, 10, 20)\n",
    "\n",
    "# 逐個切片進行近似重建\n",
    "T_approx = np.empty_like(T)\n",
    "for k in range(T.shape[2]):\n",
    "    Ck = C[:, :, k]         # 形狀: (20, 10)\n",
    "    Wk = W[:, :, k]         # 形狀: (10, 10)\n",
    "    Rk = R[:, :, k]         # 形狀: (10, 20)\n",
    "    \n",
    "    # 計算 Wk 的偽逆\n",
    "    pinv_Wk = np.linalg.pinv(Wk)  # 形狀: (10, 10)\n",
    "    \n",
    "    # 重建該切片\n",
    "    T_approx[:, :, k] = Ck @ pinv_Wk @ Rk\n",
    "\n",
    "# 計算並印出誤差\n",
    "error = np.linalg.norm(T - T_approx)\n",
    "print(f\"TCI 近似誤差: {error:.6f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3.1 生成低秩矩陣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始矩陣 A:\n",
      "[[0.77587306 0.8388079  0.58603833 0.7918035  0.56059093 0.44810269\n",
      "  1.20266936 0.92399641]\n",
      " [0.89398613 0.83720728 0.77419213 1.02608462 0.68371066 0.55772099\n",
      "  1.34172139 1.08150396]\n",
      " [0.66850849 0.85535326 0.40345924 0.56556702 0.44426592 0.34362761\n",
      "  1.08141057 0.77885624]\n",
      " [0.25653771 0.20488477 0.24921995 0.32555126 0.20652923 0.17136612\n",
      "  0.37297723 0.3149546 ]\n",
      " [0.67795493 0.839401   0.43061656 0.59822527 0.4587366  0.35746189\n",
      "  1.08714247 0.79351505]\n",
      " [0.57203671 0.58138687 0.46042722 0.61637602 0.42413931 0.34224202\n",
      "  0.8740875  0.68607246]\n",
      " [0.31645101 0.19014392 0.35532049 0.45664482 0.27305218 0.23143073\n",
      "  0.43876818 0.39666566]\n",
      " [0.52784105 0.41507622 0.51774758 0.67554623 0.42684092 0.35467255\n",
      "  0.76521314 0.64888219]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 生成一個低秩矩陣 (rank-2)\n",
    "m, n = 8, 8\n",
    "U = np.random.rand(m, 2)  # 左矩陣\n",
    "V = np.random.rand(2, n)  # 右矩陣\n",
    "A = U @ V  # 低秩矩陣\n",
    "\n",
    "print(\"原始矩陣 A:\")\n",
    "print(A)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 矩陣交叉插值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始張量 T:\n",
      "[[0.44547913 0.06006154 0.10415725 0.90626727 0.99492274 0.00228495\n",
      "  0.79694964 0.41673096]\n",
      " [0.47995228 0.57931006 0.35666205 0.25582445 0.79498201 0.21552635\n",
      "  0.17908936 0.14200637]\n",
      " [0.21590419 0.97964046 0.84394416 0.86136426 0.32076566 0.96357178\n",
      "  0.46090256 0.71409378]\n",
      " [0.72606358 0.09340448 0.23219008 0.26367008 0.55251163 0.46374746\n",
      "  0.02839732 0.33140086]\n",
      " [0.0235729  0.06193188 0.2307258  0.27738855 0.57066618 0.10268237\n",
      "  0.07061079 0.38007721]\n",
      " [0.23295281 0.78243964 0.90622222 0.63073138 0.69345918 0.31217653\n",
      "  0.83935614 0.56862306]\n",
      " [0.31178059 0.09004712 0.2542106  0.52572142 0.22141936 0.65199897\n",
      "  0.94849556 0.21496246]\n",
      " [0.61736485 0.54867869 0.30539838 0.95138685 0.76435309 0.56593755\n",
      "  0.66666494 0.5452999 ]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(47896512)\n",
    "T = np.random.rand(8, 8)\n",
    "print(\"原始張量 T:\")\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "近似矩陣 A_approx:\n",
      "[[0.44547913 0.06006154 0.10415725 0.90626727 0.99492274 0.00228495\n",
      "  0.79694964 0.41673096]\n",
      " [0.47995228 0.57931006 0.35666205 0.25582445 0.79498201 0.21552635\n",
      "  0.17908936 0.14200637]\n",
      " [0.21590419 0.97964046 0.84394416 0.86136426 0.32076566 0.96357178\n",
      "  0.46090256 0.71409378]\n",
      " [0.72606358 0.09340448 0.23219008 0.26367008 0.55251163 0.46374746\n",
      "  0.02839732 0.33140086]\n",
      " [0.0235729  0.06193188 0.2307258  0.27738855 0.57066618 0.10268237\n",
      "  0.07061079 0.38007721]\n",
      " [0.23295281 0.78243964 0.90622222 0.63073138 0.69345918 0.31217653\n",
      "  0.83935614 0.56862306]\n",
      " [0.31178059 0.09004712 0.2542106  0.52572142 0.22141936 0.65199897\n",
      "  0.94849556 0.21496246]\n",
      " [0.61736485 0.54867869 0.30539838 0.95138685 0.76435309 0.56593755\n",
      "  0.66666494 0.5452999 ]]\n",
      "Frobenius Norm 誤差: 3.27338e+00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def cross_interpolation(A, rank=2):\n",
    "    \"\"\" 矩陣交叉插值 (Cross Interpolation, CI) 方法 \"\"\"\n",
    "    m, n = A.shape\n",
    "\n",
    "    # 1. 選擇 rank 個行與列 (這裡隨機選擇)\n",
    "    row_idx = np.random.choice(m, rank, replace=False)\n",
    "    col_idx = np.random.choice(n, rank, replace=False)\n",
    "\n",
    "    # 2. 取得交叉區塊 P\n",
    "    P = A[np.ix_(row_idx, col_idx)]\n",
    "    \n",
    "    # 3. 取得 C 和 R\n",
    "    C = A[:, col_idx]  # 取選定列\n",
    "    R = A[row_idx, :]  # 取選定行\n",
    "\n",
    "    # 4. 計算 U = P^(-1)\n",
    "    P_inv = np.linalg.pinv(P)  # 使用偽逆以應對可能的數值問題\n",
    "\n",
    "    # 5. 近似 A\n",
    "    A_approx = C @ P_inv @ R\n",
    "\n",
    "    return A_approx, row_idx, col_idx\n",
    "\n",
    "# 執行 CI 方法\n",
    "A_approx, row_idx, col_idx = cross_interpolation(T, rank=8)\n",
    "\n",
    "# 顯示近似結果\n",
    "print(\"近似矩陣 A_approx:\")\n",
    "print(A_approx)\n",
    "\n",
    "# 計算誤差\n",
    "error = np.linalg.norm(A - A_approx, ord='fro')\n",
    "print(f\"Frobenius Norm 誤差: {error:.5e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCI error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types  import SimpleNamespace\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def rook_pivoting(A: np.ndarray, k: int, nRookIter: int) -> Tuple[int, int, float]:\n",
    "    max_iter = nRookIter\n",
    "    rows = np.arange(k, A.shape[0])\n",
    "    cols = np.arange(k, A.shape[1])\n",
    "    i0, j0 = k, k\n",
    "    err = abs(A[i0, j0])\n",
    "    for _ in range(max_iter):\n",
    "        # 找 column 最大值\n",
    "        col_abs = np.abs(A[rows, j0])\n",
    "        i_rel = np.argmax(col_abs)\n",
    "        i_new = rows[i_rel]\n",
    "\n",
    "        # 找 row 最大值\n",
    "        row_abs = np.abs(A[i_new, cols])\n",
    "        j_rel = np.argmax(row_abs)\n",
    "        j_new = cols[j_rel]\n",
    "\n",
    "        if i_new == i0 and j_new == j0:\n",
    "            err = abs(A[i0, j0])\n",
    "            break\n",
    "        else:\n",
    "            i0, j0 = i_new, j_new\n",
    "            err = abs(A[i0, j0])\n",
    "    return i0, j0, err\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_interpolation(A, rank, k=0, nRookIter=8): \n",
    "    \"\"\"矩陣交叉插值 (Cross Interpolation, CI) 方法\"\"\"\n",
    "    i0, j0, err = rook_pivoting(A, k, nRookIter)  # 用 k 而非 rank 當作起始索引\n",
    "    # 這裡暫時只取單一 pivot\n",
    "    row_idx = [i0]\n",
    "    col_idx = [j0]\n",
    "    # 取得交叉區塊 P\n",
    "    P = A[np.ix_(row_idx, col_idx)]\n",
    "    \n",
    "    # 取得 C 和 R\n",
    "    C = A[:, col_idx]  # 取選定的列\n",
    "    R = A[row_idx, :]  # 取選定的行\n",
    "\n",
    "    # 計算偽逆\n",
    "    P_inv = np.linalg.pinv(P)\n",
    "\n",
    "    # 近似 A\n",
    "    A_approx = C @ P_inv @ R\n",
    "\n",
    "    return A_approx, row_idx, col_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport matplotlib.pyplot as plt\\nA = np.random.rand(8, 8)\\nA_approx, row_idx, col_idx = cross_interpolation(A, rank=7, k=0, nRookIter=1)\\n\\nerror = np.linalg.norm(A - A_approx, ord=\\'fro\\')\\nprint(f\"Frobenius Norm 誤差: {error:.5e}\")\\nprint(\"擬和\",A_approx)\\nprint(\"原始\",A)\\nnRookIters = range(1, 20)\\nerrors = []\\n\\nfor nRookIter in nRookIters:\\n    A_approx, _, _ = cross_interpolation(A, rank=7,nRookIter=nRookIter)\\n    error = np.linalg.norm(A - A_approx, ord=\\'fro\\')\\n    errors.append(error)\\n\\nplt.plot(nRookIters, errors, marker=\\'o\\')\\nplt.xlabel(\\'nRookIter\\')\\nplt.ylabel(\\'Frobenius Norm Error\\')\\nplt.title(\\'Error vs. nRookIter for Cross Interpolation\\')\\nplt.grid(True)\\nplt.show()\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "A = np.random.rand(8, 8)\n",
    "A_approx, row_idx, col_idx = cross_interpolation(A, rank=7, k=0, nRookIter=1)\n",
    "\n",
    "error = np.linalg.norm(A - A_approx, ord='fro')\n",
    "print(f\"Frobenius Norm 誤差: {error:.5e}\")\n",
    "print(\"擬和\",A_approx)\n",
    "print(\"原始\",A)\n",
    "nRookIters = range(1, 20)\n",
    "errors = []\n",
    "\n",
    "for nRookIter in nRookIters:\n",
    "    A_approx, _, _ = cross_interpolation(A, rank=7,nRookIter=nRookIter)\n",
    "    error = np.linalg.norm(A - A_approx, ord='fro')\n",
    "    errors.append(error)\n",
    "\n",
    "plt.plot(nRookIters, errors, marker='o')\n",
    "plt.xlabel('nRookIter')\n",
    "plt.ylabel('Frobenius Norm Error')\n",
    "plt.title('Error vs. nRookIter for Cross Interpolation')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCI with  SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "奇異值 S:\n",
      "[3.95287876 1.24380494 0.94162248 0.78930132 0.50966789 0.38069747\n",
      " 0.20605066 0.0525982 ]\n",
      "奇異值能量累積比率:\n",
      "[0.4894223  0.64342294 0.76000912 0.85773579 0.92083988 0.96797561\n",
      " 0.9934876  1.        ]\n",
      "降維前矩陣的 CI 近似誤差: 3.41233e+00\n",
      "降維後矩陣的 CI 近似誤差: 3.27609e+00\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(47896512)\n",
    "T = np.random.rand(8, 8)\n",
    "# SVD 分解\n",
    "U, S, Vt = np.linalg.svd(T)\n",
    "\n",
    "# 顯示奇異值\n",
    "print(\"奇異值 S:\")\n",
    "print(S)\n",
    "\n",
    "# 計算能量累積\n",
    "energy_ratio = np.cumsum(S) / np.sum(S)\n",
    "print(\"奇異值能量累積比率:\")\n",
    "print(energy_ratio)\n",
    "\n",
    "def low_rank_approximation(A, rank):\n",
    "    \"\"\" 透過 SVD 降維來建立低秩矩陣 \"\"\"\n",
    "    U, S, Vt = np.linalg.svd(A)\n",
    "    S[rank:] = 0  # 只保留前 rank 個奇異值\n",
    "    return U @ np.diag(S) @ Vt\n",
    "\n",
    "# 降維到 rank=4\n",
    "T_low_rank = low_rank_approximation(T, rank=4)\n",
    "\n",
    "# 執行 CI 方法\n",
    "A_approx, row_idx, col_idx = cross_interpolation(T_low_rank, rank=8)\n",
    "A_approx_B, row_idx_B, col_idx_B = cross_interpolation(T, rank=8)\n",
    "# 計算誤差\n",
    "error_after = np.linalg.norm(T_low_rank - A_approx, ord='fro')\n",
    "error_before = np.linalg.norm(T - A_approx_B, ord='fro')\n",
    "print(f\"降維前矩陣的 CI 近似誤差: {error_before:.5e}\")\n",
    "print(f\"降維後矩陣的 CI 近似誤差: {error_after:.5e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tci by max min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from types import SimpleNamespace\n",
    "from typing import Tuple\n",
    "\n",
    "# 生成一個 20x20x20 的張量\n",
    "np.random.seed(47896512)\n",
    "T = np.random.rand(20, 20, 20)\n",
    "\n",
    "class TCI:\n",
    "    def __init__(self, tensor: np.ndarray, rank: int = 10, pivoting: str = \"rook\", nRookIter: int = 3):\n",
    "        \"\"\"\n",
    "        初始化 TCI 類別\n",
    "        :param tensor: 需要近似的 3D 張量\n",
    "        :param rank: 需要選取的 pivot 數量\n",
    "        :param pivoting: 使用的選擇策略 (目前只支援 rook)\n",
    "        :param nRookIter: rook pivoting 最大迭代次數\n",
    "        \"\"\"\n",
    "        self.T = tensor\n",
    "        self.rank = rank\n",
    "        self.param = SimpleNamespace(nRookIter=nRookIter)\n",
    "        self.m, self.n, self.p = tensor.shape\n",
    "\n",
    "    def rook_pivoting(self, A: np.ndarray, k: int) -> Tuple[int, int, float]:\n",
    "        \"\"\"\n",
    "        Rook pivoting: 透過最大值選擇最佳 pivot 行列\n",
    "        \"\"\"\n",
    "        max_iter = self.param.nRookIter\n",
    "        rows = np.arange(k, A.shape[0])\n",
    "        cols = np.arange(k, A.shape[1])\n",
    "        i0, j0 = k, k\n",
    "        err = abs(A[i0, j0])\n",
    "\n",
    "        for _ in range(max_iter):\n",
    "            # 找列中的最大值\n",
    "            col_abs = np.abs(A[rows, j0])\n",
    "            i_rel = np.argmax(col_abs)\n",
    "            i_new = rows[i_rel]\n",
    "            max_col = col_abs[i_rel]\n",
    "\n",
    "            # 找行中的最大值\n",
    "            row_abs = np.abs(A[i_new, cols])\n",
    "            j_rel = np.argmax(row_abs)\n",
    "            j_new = cols[j_rel]\n",
    "            max_row = row_abs[j_rel]\n",
    "\n",
    "            if i_new == i0 and j_new == j0:\n",
    "                err = abs(A[i0, j0])\n",
    "                break\n",
    "            else:\n",
    "                i0, j0 = i_new, j_new\n",
    "                err = abs(A[i0, j0])\n",
    "\n",
    "        return i0, j0, err\n",
    "\n",
    "    def select_pivots(self):\n",
    "        \"\"\"\n",
    "        使用 rook pivoting 來選擇最佳 pivot 行與列\n",
    "        \"\"\"\n",
    "        A_2D = np.mean(self.T, axis=2)  # 先對第三維度取均值，變成 2D 矩陣來選擇 pivots\n",
    "        row_idx, col_idx = [], []\n",
    "\n",
    "        for k in range(self.rank):\n",
    "            i0, j0, _ = self.rook_pivoting(A_2D, k)\n",
    "            row_idx.append(i0)\n",
    "            col_idx.append(j0)\n",
    "        \n",
    "        return np.array(row_idx), np.array(col_idx)\n",
    "\n",
    "    def compute_tci(self):\n",
    "        \"\"\"\n",
    "        執行 TCI 演算法\n",
    "        \"\"\"\n",
    "        # 透過 rook pivoting 選取最好的 pivot 行與列\n",
    "        rows, cols = self.select_pivots()\n",
    "\n",
    "        # 取出 C, W, R\n",
    "        C = self.T[:, cols, :]  # (20, 10, 20) 取選定列\n",
    "        R = self.T[rows, :, :]  # (10, 20, 20) 取選定行\n",
    "        W = self.T[np.ix_(rows, cols, np.arange(self.p))]  # (10, 10, 20) 交叉區域 (核心)\n",
    "\n",
    "        # 修正 W_inv 的維度確保其適用於矩陣乘法\n",
    "        W_inv = np.linalg.pinv(W.reshape(10, 10 * self.p)).reshape(10, 10, self.p)\n",
    "\n",
    "        # 近似重建: C (20, 10, 20) * W_inv (10, 10, 20) * R (10, 20, 20)\n",
    "        T_approx = np.einsum(\"ijk,jlk,lmk->imk\", C, W_inv, R)\n",
    "\n",
    "        return T_approx, rows, cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCI 近似誤差 (Frobenius Norm): 49.389889\n",
      "選擇的 pivot 行索引: [11 16 16 16 16 19 18  9 11 19]\n",
      "選擇的 pivot 列索引: [ 8  4  4  4  4 19 12 11  8 19]\n"
     ]
    }
   ],
   "source": [
    "# 初始化 TCI 類別\n",
    "tci = TCI(T, rank=10,nRookIter=10)\n",
    "\n",
    "# 計算 TCI\n",
    "T_approx, selected_rows, selected_cols = tci.compute_tci()\n",
    "\n",
    "# 計算誤差\n",
    "error = np.linalg.norm(T - T_approx)\n",
    "print(f\"TCI 近似誤差 (Frobenius Norm): {error:.6f}\")\n",
    "print(f\"選擇的 pivot 行索引: {selected_rows}\")\n",
    "print(f\"選擇的 pivot 列索引: {selected_cols}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## error圖片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化 TCI 類別\n",
    "tci = TCI(T, rank=10)\n",
    "\n",
    "# 計算 TCI\n",
    "T_approx, selected_rows, selected_cols = tci.compute_tci()\n",
    "\n",
    "# 計算誤差\n",
    "error = np.linalg.norm(T - T_approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nplt.plot(ranks, errors, marker='o')\\nplt.xlabel('Rank')\\nplt.ylabel('Frobenius Norm Error')\\nplt.title('Error vs. nRookIter for Cross Interpolation')\\nplt.grid(True)\\nplt.show()\\n\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nRookIters = range(1, 5)\n",
    "errors = []\n",
    "for nRookIter in nRookIters:\n",
    "    tci = TCI(T, rank=10,nRookIter=nRookIter)\n",
    "    T_approx, selected_rows, selected_cols = tci.compute_tci()\n",
    "    error = np.linalg.norm(T - T_approx)\n",
    "    errors.append(error)\n",
    "    \n",
    "'''\n",
    "plt.plot(ranks, errors, marker='o')\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('Frobenius Norm Error')\n",
    "plt.title('Error vs. nRookIter for Cross Interpolation')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prrLU 近似誤差: 3.37699e+00\n",
      "選擇的 pivot 行索引: [1, 6, 6, 4]\n",
      "選擇的 pivot 列索引: [3, 2, 2, 7]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg\n",
    "\n",
    "class prrLU:\n",
    "    def __init__(self, A: np.ndarray, rank: int):\n",
    "        \"\"\"\n",
    "        部分秩揭露 LU 分解\n",
    "        :param A: 需要分解的矩陣\n",
    "        :param rank: 近似的目標 rank\n",
    "        \"\"\"\n",
    "        self.A = A.copy()\n",
    "        self.rank = rank\n",
    "        self.m, self.n = A.shape\n",
    "        self.P = np.eye(self.m)\n",
    "        self.L = np.zeros((self.m, self.rank))\n",
    "        self.U = np.zeros((self.rank, self.n))\n",
    "        self.row_idx = []\n",
    "        self.col_idx = []\n",
    "\n",
    "    def rook_pivoting(self, A, k):\n",
    "        \"\"\"\n",
    "        使用 rook pivoting 選擇最大值來決定 pivot 行列\n",
    "        \"\"\"\n",
    "        max_iter = 3\n",
    "        rows = np.arange(k, A.shape[0])\n",
    "        cols = np.arange(k, A.shape[1])\n",
    "        i0, j0 = k, k\n",
    "        err = abs(A[i0, j0])\n",
    "\n",
    "        for _ in range(max_iter):\n",
    "            # 找列中的最大值\n",
    "            col_abs = np.abs(A[rows, j0])\n",
    "            i_rel = np.argmax(col_abs)\n",
    "            i_new = rows[i_rel]\n",
    "\n",
    "            # 找行中的最大值\n",
    "            row_abs = np.abs(A[i_new, cols])\n",
    "            j_rel = np.argmax(row_abs)\n",
    "            j_new = cols[j_rel]\n",
    "\n",
    "            if i_new == i0 and j_new == j0:\n",
    "                break\n",
    "            else:\n",
    "                i0, j0 = i_new, j_new\n",
    "                err = abs(A[i0, j0])\n",
    "\n",
    "        return i0, j0, err\n",
    "\n",
    "    def compute_prrLU(self):\n",
    "        \"\"\"\n",
    "        執行 prrLU 分解\n",
    "        \"\"\"\n",
    "        A = self.A.copy()\n",
    "        for k in range(self.rank):\n",
    "            # 選擇最佳 pivot\n",
    "            i0, j0, _ = self.rook_pivoting(A, k)\n",
    "            self.row_idx.append(i0)\n",
    "            self.col_idx.append(j0)\n",
    "\n",
    "            # 交換 pivot 行與列\n",
    "            A[[k, i0], :] = A[[i0, k], :]\n",
    "            A[:, [k, j0]] = A[:, [j0, k]]\n",
    "\n",
    "            # 計算 L 和 U\n",
    "            self.L[k + 1:, k] = A[k + 1:, k] / A[k, k]\n",
    "            self.U[k, k:] = A[k, k:]\n",
    "\n",
    "            # 更新 A\n",
    "            A[k + 1:, k + 1:] -= np.outer(self.L[k + 1:, k], self.U[k, k + 1:])\n",
    "\n",
    "        return self.P, self.L, self.U, self.row_idx, self.col_idx\n",
    "\n",
    "# 測試 prrLU\n",
    "np.random.seed(42)\n",
    "A = np.random.rand(8, 8)\n",
    "\n",
    "prrlu = prrLU(A, rank=4)\n",
    "P, L, U, row_idx, col_idx = prrlu.compute_prrLU()\n",
    "\n",
    "# 驗證 prrLU 近似\n",
    "A_approx = P @ L @ U\n",
    "error = np.linalg.norm(A - A_approx)\n",
    "\n",
    "print(f\"prrLU 近似誤差: {error:.5e}\")\n",
    "print(f\"選擇的 pivot 行索引: {row_idx}\")\n",
    "print(f\"選擇的 pivot 列索引: {col_idx}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCI + prrLU + Schur 補"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCI + prrLU 近似誤差 (Frobenius Norm): 1.692602e+01\n",
      "選擇的 pivot 行索引: [5 7 4 9 0 6 3 8 2 1]\n",
      "選擇的 pivot 列索引: [5 8 9 7 3 1 4 0 6 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import lu\n",
    "\n",
    "class TCI_Schur:\n",
    "    def __init__(self, tensor: np.ndarray, rank: int = 10):\n",
    "        \"\"\"\n",
    "        結合 prrLU、TCI 和 Schur 補\n",
    "        :param tensor: 需要近似的 3D 張量\n",
    "        :param rank: 需要選取的 pivot 數量\n",
    "        \"\"\"\n",
    "        self.T = tensor\n",
    "        self.rank = rank\n",
    "        self.m, self.n, self.p = tensor.shape\n",
    "\n",
    "    def compute_prrLU(self, A):\n",
    "        \"\"\"\n",
    "        使用 prrLU 來選擇最佳 pivot 行與列\n",
    "        :param A: 需要進行 prrLU 分解的 2D 矩陣\n",
    "        :return: pivot 行與列索引\n",
    "        \"\"\"\n",
    "        L, U = lu(A, permute_l=True)\n",
    "        row_idx = np.argsort(np.abs(L[:, 0]))[-self.rank:]  # 挑選影響最大的行\n",
    "        col_idx = np.argsort(np.abs(U[0, :]))[-self.rank:]  # 挑選影響最大的列\n",
    "        return row_idx, col_idx\n",
    "\n",
    "    def compute_schur(self, W, C, R):\n",
    "        \"\"\"\n",
    "        計算 Schur 補來修正誤差\n",
    "        \"\"\"\n",
    "        W_inv = np.linalg.pinv(W.reshape(self.rank, self.rank * self.p)).reshape(self.rank, self.rank, self.p)\n",
    "        A_approx = np.einsum(\"ijk,jlk,lmk->imk\", C, W_inv, R)\n",
    "        residual = self.T - A_approx  # 計算殘差矩陣\n",
    "        return residual\n",
    "\n",
    "    def compute_tci_schur(self):\n",
    "        \"\"\"\n",
    "        執行 TCI + prrLU + Schur 補\n",
    "        \"\"\"\n",
    "        # 先取 T 在第三維上的平均，轉為 2D 矩陣來進行 prrLU\n",
    "        A_2D = np.mean(self.T, axis=2)\n",
    "\n",
    "        # 使用 prrLU 來選擇最好的 pivot 行與列\n",
    "        rows, cols = self.compute_prrLU(A_2D)\n",
    "\n",
    "        # 取出 C, R, W\n",
    "        C = self.T[:, cols, :]  # (20, rank, 20) 取選定列\n",
    "        R = self.T[rows, :, :]  # (rank, 20, 20) 取選定行\n",
    "        W = self.T[np.ix_(rows, cols, np.arange(self.p))]  # (rank, rank, 20) 交叉區域\n",
    "\n",
    "        # 計算 Schur 補\n",
    "        S = self.compute_schur(W, C, R)\n",
    "\n",
    "        # 計算 W 的偽逆\n",
    "        W_inv = np.linalg.pinv(W.reshape(self.rank, self.rank * self.p)).reshape(self.rank, self.rank, self.p)\n",
    "\n",
    "        # 近似重建 T + Schur 修正\n",
    "        T_approx = np.einsum(\"ijk,jlk,lmk->imk\", C, W_inv, R) \n",
    "\n",
    "        return T_approx, rows, cols\n",
    "\n",
    "# 生成 20x20x20 張量\n",
    "np.random.seed(47896512)\n",
    "T = np.random.rand(10, 10, 10)\n",
    "\n",
    "# 初始化 TCI_Schur 類別\n",
    "tci_schur = TCI_Schur(T, rank=10)\n",
    "\n",
    "# 計算 TCI + prrLU + Schur 補\n",
    "T_approx, selected_rows, selected_cols = tci_schur.compute_tci_schur()\n",
    "\n",
    "# 計算誤差\n",
    "error = np.linalg.norm(T - T_approx)\n",
    "print(f\"TCI + prrLU 近似誤差 (Frobenius Norm): {error:.6e}\")\n",
    "\n",
    "print(f\"選擇的 pivot 行索引: {selected_rows}\")\n",
    "print(f\"選擇的 pivot 列索引: {selected_cols}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Schur 補到底加了多少魔法??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCI + prrLU + Schur 近似誤差 (Frobenius Norm): 5.700633e-07\n",
      "初始低階近似 A_approx 的 Frobenius Norm: 2.980450e+00\n",
      "Schur 補 S 的 Frobenius Norm: 1.692602e+01\n",
      "Schur 補在 T 中的比例: 93.32%\n",
      "選擇的 pivot 行索引: [5 7 4 9 0 6 3 8 2 1]\n",
      "選擇的 pivot 列索引: [5 8 9 7 3 1 4 0 6 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import lu\n",
    "\n",
    "class TCI_Schur:\n",
    "    def __init__(self, tensor: np.ndarray, rank: int = 10):\n",
    "        \"\"\"\n",
    "        結合 prrLU、TCI 和 Schur 補\n",
    "        :param tensor: 需要近似的 3D 張量\n",
    "        :param rank: 需要選取的 pivot 數量\n",
    "        \"\"\"\n",
    "        # 可考慮轉為 float32 減少精度，方便觀察數值誤差\n",
    "        self.T = tensor.astype(np.float32)\n",
    "        self.rank = rank\n",
    "        self.m, self.n, self.p = self.T.shape\n",
    "\n",
    "    def compute_prrLU(self, A):\n",
    "        \"\"\"\n",
    "        使用 prrLU 來選擇最佳 pivot 行與列\n",
    "        :param A: 需要進行 prrLU 分解的 2D 矩陣\n",
    "        :return: pivot 行與列索引\n",
    "        \"\"\"\n",
    "        # 注意：這裡採用 permute_l=True 回傳兩個矩陣\n",
    "        L, U = lu(A, permute_l=True)\n",
    "        row_idx = np.argsort(np.abs(L[:, 0]))[-self.rank:]  # 挑選影響最大的行\n",
    "        col_idx = np.argsort(np.abs(U[0, :]))[-self.rank:]  # 挑選影響最大的列\n",
    "        return row_idx, col_idx\n",
    "\n",
    "    def compute_schur(self, W, C, R, W_inv):\n",
    "        \"\"\"\n",
    "        計算 Schur 補來修正誤差\n",
    "        \"\"\"\n",
    "        A_approx = np.einsum(\"ijk,jlk,lmk->imk\", C, W_inv, R)\n",
    "        residual = self.T - A_approx  # 計算殘差矩陣，也就是 Schur 補\n",
    "        return residual\n",
    "\n",
    "    def compute_tci_schur(self):\n",
    "        \"\"\"\n",
    "        執行 TCI + prrLU + Schur 補，並回傳 Schur 補 S 以便分析其貢獻\n",
    "        \"\"\"\n",
    "        # 先取 T 在第三維上的平均，轉為 2D 矩陣來進行 prrLU\n",
    "        A_2D = np.mean(self.T, axis=2)\n",
    "\n",
    "        # 使用 prrLU 來選擇最好的 pivot 行與列\n",
    "        rows, cols = self.compute_prrLU(A_2D)\n",
    "\n",
    "        # 取出 C, R, W\n",
    "        C = self.T[:, cols, :]  # (m, rank, p)\n",
    "        R = self.T[rows, :, :]  # (rank, n, p)\n",
    "        W = self.T[np.ix_(rows, cols, np.arange(self.p))]  # (rank, rank, p)\n",
    "\n",
    "        # 計算 W 的偽逆 (針對每個 p 進行偽逆計算)\n",
    "        W_inv = np.linalg.pinv(W.reshape(self.rank, self.rank * self.p)).reshape(self.rank, self.rank, self.p)\n",
    "\n",
    "        # 計算初始低階近似\n",
    "        A_approx = np.einsum(\"ijk,jlk,lmk->imk\", C, W_inv, R)\n",
    "        # 計算 Schur 補 S\n",
    "        S = self.compute_schur(W, C, R, W_inv)\n",
    "        # 最終近似：原本的低階近似加上 Schur 補\n",
    "        T_approx = A_approx + S\n",
    "\n",
    "        # 為方便分析，也回傳 A_approx\n",
    "        return T_approx, A_approx, S, rows, cols\n",
    "\n",
    "# 測試用例：生成較低精度且規模較大的 tensor\n",
    "np.random.seed(47896512)\n",
    "T = np.random.rand(10, 10, 10).astype(np.float64)\n",
    "\n",
    "# 初始化 TCI_Schur 類別\n",
    "tci_schur = TCI_Schur(T, rank=10)\n",
    "\n",
    "# 執行 TCI + prrLU + Schur 補\n",
    "T_approx, A_approx, S, selected_rows, selected_cols = tci_schur.compute_tci_schur()\n",
    "\n",
    "# 計算誤差\n",
    "total_error = np.linalg.norm(T - T_approx)\n",
    "schur_norm = np.linalg.norm(S)\n",
    "approx_norm = np.linalg.norm(A_approx)\n",
    "T_norm = np.linalg.norm(T)\n",
    "\n",
    "print(f\"TCI + prrLU + Schur 近似誤差 (Frobenius Norm): {total_error:.6e}\")\n",
    "print(f\"初始低階近似 A_approx 的 Frobenius Norm: {approx_norm:.6e}\")\n",
    "print(f\"Schur 補 S 的 Frobenius Norm: {schur_norm:.6e}\")\n",
    "print(f\"Schur 補在 T 中的比例: {(schur_norm/T_norm)*100:.2f}%\")\n",
    "print(f\"選擇的 pivot 行索引: {selected_rows}\")\n",
    "print(f\"選擇的 pivot 列索引: {selected_cols}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## schur and nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "改進後 TCI + prrLU + Schur 近似誤差: 4.435625e+01\n",
      "選點數量: 10\n",
      "選擇的 pivot 行索引: [18 11  1 12  3  9 16 19 14  6]\n",
      "選擇的 pivot 列索引: [10  1 13  0  8 18 17  7 19  4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import lu\n",
    "\n",
    "class TCI_Schur_Improved:\n",
    "    def __init__(self, tensor: np.ndarray, rank: int = 10, pivoting: str = \"rook\",\n",
    "                 nRookIter: int = 3, schur_weight: float = 0.1, regularization: float = 1e-5):\n",
    "        \"\"\"\n",
    "        改進版 TCI + prrLU/rook pivoting + Schur 補\n",
    "        :param tensor: 需要近似的 3D 張量\n",
    "        :param rank: 需要選取的 pivot 數量\n",
    "        :param pivoting: pivot 選擇策略，\"rook\" 或 \"prrLU\"\n",
    "        :param nRookIter: rook pivoting 的最大迭代次數\n",
    "        :param schur_weight: 控制 Schur 補的影響力 (介於 0 到 1)\n",
    "        :param regularization: W 矩陣正則化參數，避免數值問題\n",
    "        \"\"\"\n",
    "        self.m, self.n, self.p = tensor.shape\n",
    "        self.rank = min(rank, min(self.m, self.n))  # 確保不超出矩陣維度\n",
    "        self.T = tensor.astype(np.float64)\n",
    "        self.pivoting = pivoting\n",
    "        self.nRookIter = nRookIter\n",
    "        self.schur_weight = schur_weight\n",
    "        self.regularization = regularization\n",
    "\n",
    "    def compute_prrLU(self, A):\n",
    "        \"\"\"\n",
    "        使用 prrLU 來選擇最佳 pivot 行與列，這裡以行列範數做排序\n",
    "        \"\"\"\n",
    "        row_norms = np.linalg.norm(A, axis=1)\n",
    "        col_norms = np.linalg.norm(A, axis=0)\n",
    "        row_idx = np.argsort(row_norms)[-self.rank:]\n",
    "        col_idx = np.argsort(col_norms)[-self.rank:]\n",
    "        return row_idx, col_idx\n",
    "\n",
    "    def rook_pivoting(self, A: np.ndarray, k: int):\n",
    "        \"\"\"\n",
    "        Rook pivoting：從 A 的子矩陣（從 k 開始）中選取一個 pivot，\n",
    "        並透過 nRookIter 次迭代來改善選點品質\n",
    "        \"\"\"\n",
    "        max_iter = self.nRookIter\n",
    "        rows = np.arange(k, A.shape[0])\n",
    "        cols = np.arange(k, A.shape[1])\n",
    "        i0, j0 = k, k\n",
    "        for _ in range(max_iter):\n",
    "            i_new = rows[np.argmax(np.abs(A[rows, j0]))]\n",
    "            j_new = cols[np.argmax(np.abs(A[i_new, cols]))]\n",
    "            if i_new == i0 and j_new == j0:\n",
    "                break\n",
    "            i0, j0 = i_new, j_new\n",
    "        pivot_val = abs(A[i0, j0])\n",
    "        return i0, j0, pivot_val\n",
    "\n",
    "    def select_pivots(self, A_2D):\n",
    "        \"\"\"\n",
    "        根據 pivoting 策略選擇 pivot 行與列索引\n",
    "        \"\"\"\n",
    "        if self.pivoting == \"rook\":\n",
    "            row_idx = []\n",
    "            col_idx = []\n",
    "            for k in range(self.rank):\n",
    "                i0, j0, _ = self.rook_pivoting(A_2D, k)\n",
    "                row_idx.append(i0)\n",
    "                col_idx.append(j0)\n",
    "            return np.array(row_idx), np.array(col_idx)\n",
    "        else:\n",
    "            return self.compute_prrLU(A_2D)\n",
    "\n",
    "    def compute_schur(self, W, C, R, W_inv):\n",
    "        \"\"\"\n",
    "        計算 Schur 補，並以 schur_weight 調整其影響力\n",
    "        \"\"\"\n",
    "        A_approx = np.einsum(\"ijk,jlk,lmk->imk\", C, W_inv, R)\n",
    "        residual = self.T - A_approx\n",
    "        return self.schur_weight * residual\n",
    "\n",
    "    def compute_tci_schur(self):\n",
    "        \"\"\"\n",
    "        執行改進版 TCI + pivoting + Schur 補，回傳最終近似、初始近似、Schur 補、\n",
    "        pivot 行與列索引，以及選點數量\n",
    "        \"\"\"\n",
    "        # 將 tensor 沿第三維取均值，形成 2D 矩陣供 pivot 選取\n",
    "        A_2D = np.mean(self.T, axis=2)\n",
    "        rows, cols = self.select_pivots(A_2D)\n",
    "        pivot_count = len(rows)\n",
    "\n",
    "        # 擷取 C, R, W (注意各自的維度)\n",
    "        C = self.T[:, cols, :]              # (m, rank, p)\n",
    "        R = self.T[rows, :, :]               # (rank, n, p)\n",
    "        W = self.T[np.ix_(rows, cols, np.arange(self.p))]  # (rank, rank, p)\n",
    "\n",
    "        # 對 W 進行正則化以改善條件數\n",
    "        W_reg = W + self.regularization * np.eye(self.rank)[:, :, np.newaxis]\n",
    "\n",
    "        # 計算 W 的偽逆\n",
    "        W_inv = np.linalg.pinv(W_reg.reshape(self.rank, self.rank * self.p)).reshape(self.rank, self.rank, self.p)\n",
    "\n",
    "        # 計算初始低階近似\n",
    "        A_approx = np.einsum(\"ijk,jlk,lmk->imk\", C, W_inv, R)\n",
    "\n",
    "        # 計算 Schur 補 (並加入權重)\n",
    "        S = self.compute_schur(W, C, R, W_inv)\n",
    "\n",
    "        # 得到最終 TCI 近似\n",
    "        T_approx = A_approx + S\n",
    "\n",
    "        return T_approx, A_approx, S, rows, cols, pivot_count\n",
    "\n",
    "# === 測試程式 ===\n",
    "if __name__ == '__main__':\n",
    "    np.random.seed(47896512)\n",
    "    T = np.random.rand(20, 20, 20)\n",
    "    \n",
    "    # 使用 \"prrLU\" 或 \"rook\" 都可以試試，這裡示範 prrLU 策略\n",
    "    tci_schur_improved = TCI_Schur_Improved(T, rank=10, pivoting=\"prrLU\",\n",
    "                                              schur_weight=0.1, regularization=1e-5)\n",
    "    T_approx, A_approx, S, selected_rows, selected_cols, pivot_count = tci_schur_improved.compute_tci_schur()\n",
    "\n",
    "    error = np.linalg.norm(T - T_approx)\n",
    "    print(f\"改進後 TCI + prrLU + Schur 近似誤差: {error:.6e}\")\n",
    "    print(f\"選點數量: {pivot_count}\")\n",
    "    print(f\"選擇的 pivot 行索引: {selected_rows}\")\n",
    "    print(f\"選擇的 pivot 列索引: {selected_cols}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finRL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
